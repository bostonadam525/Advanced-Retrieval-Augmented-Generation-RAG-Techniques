{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-user ReAct Agent Chatbot in LangChain\n",
        "* Notebook by Adam Lang\n",
        "* Date: 10/2/2024\n",
        "\n",
        "# Overview\n",
        "* In this notebook we will build a multi-user ReAct AI Agent chatbot using LangChain Legacy Syntax.\n",
        "* Tools we will use:\n",
        "1. web search -- Tavily API\n",
        "2. weather API\n",
        "* To make this \"Multi-user\" we will store the converation in memory."
      ],
      "metadata": {
        "id": "Jx3ITGnnhfYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "dly_g6-li3Pj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HSR99Vbceax",
        "outputId": "fc5773f6-0129-4ddb-dd72-aa8a494960ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.2.0\n",
            "  Downloading langchain-0.2.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (3.10.8)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.2.0)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain==0.2.0)\n",
            "  Downloading langchain_core-0.2.41-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.0)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.0)\n",
            "  Downloading langsmith-0.1.130-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (2.32.3)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.2.0)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (2.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.13.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (4.12.2)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.2.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.2.0) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.0) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain==0.2.0)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.2.0)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.2.2)\n",
            "Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_core-0.2.41-py3-none-any.whl (397 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.0/397.0 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.130-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, requests-toolbelt, jsonpatch, httpcore, httpx, dataclasses-json, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.0 langchain-core-0.2.41 langchain-text-splitters-0.2.4 langsmith-0.1.130 marshmallow-3.22.0 mypy-extensions-1.0.0 orjson-3.10.7 requests-toolbelt-1.0.0 tenacity-8.5.0 typing-inspect-0.9.0\n",
            "Collecting langchain-openai==0.1.7\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.7) (0.2.41)\n",
            "Collecting openai<2.0.0,>=1.24.0 (from langchain-openai==0.1.7)\n",
            "  Downloading openai-1.51.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.1.7)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (0.1.130)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.27.2)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (4.66.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.7) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.7) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (3.10.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.1.7) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.1.7) (2.2.3)\n",
            "Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
            "Downloading openai-1.51.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.5/383.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, tiktoken, openai, langchain-openai\n",
            "Successfully installed jiter-0.5.0 langchain-openai-0.1.7 openai-1.51.0 tiktoken-0.7.0\n",
            "Collecting langchain-community==0.2.0\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (3.10.8)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (0.2.0)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (0.2.41)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (0.1.130)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (2.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.2.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (3.10.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.2.0) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.2.2)\n",
            "Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-community\n",
            "Successfully installed langchain-community-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.2.0\n",
        "!pip install langchain-openai==0.1.7\n",
        "!pip install langchain-community==0.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Open AI API Key"
      ],
      "metadata": {
        "id": "DXepheO2jO5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass(\"Enter your OPEN AI API KEY: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc4Uv1MnjFWB",
        "outputId": "81b5643b-a050-47b7-d6dd-2082c77f1e60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OPEN AI API KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Tavily Search API Key"
      ],
      "metadata": {
        "id": "HRnbnszFjfbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TAVILY_API_KEY = getpass(\"Enter your TAVILY API KEY: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2cZMYoNjWvk",
        "outputId": "bbfb0613-d5d0-4469-b1f6-304eaa3bf704"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your TAVILY API KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter WeatherAPI Key"
      ],
      "metadata": {
        "id": "yvdkKJgdj88T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WEATHER_API_KEY = getpass(\"Enter your WeatherAPI KEY: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki6a3tLfj6Eq",
        "outputId": "4f42beec-1feb-4330-fd6b-21c68c796883"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your WeatherAPI KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Environment Variables"
      ],
      "metadata": {
        "id": "JkefD1RikSGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
      ],
      "metadata": {
        "id": "vLL7LS5UkLOd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Custom Tools\n",
        "* We are going to create 2 custom tools which will serve as wrappers on top of the **TAVILY API** and **WEATHER API** respectively.\n",
        "* The tools are:\n",
        "  * 1) Simple Web Search Tool\n",
        "  * 2) Weather tool"
      ],
      "metadata": {
        "id": "W_MVhf2Zkg74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## imports\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults ## Tavily search\n",
        "from langchain_core.tools import tool ## tool\n",
        "import requests\n",
        "import json\n",
        "\n",
        "## instantiate tavily search\n",
        "tv_search = TavilySearchResults(max_results=3,\n",
        "                                search_depth='advanced',\n",
        "                                max_tokens=10000)\n",
        "\n",
        "## search tool\n",
        "@tool\n",
        "def search_web(query: str) -> list:\n",
        "  \"\"\"Custom tool to search web for a query.\"\"\"\n",
        "  tavily_tool = TavilySearchResults(max_results=2) ## returns list of search results\n",
        "  results = tavily_tool.invoke(query) ## invoke tool with query\n",
        "  return results\n",
        "\n",
        "\n",
        "## weather tool\n",
        "@tool\n",
        "def get_weather(query: str) -> list:\n",
        "  \"\"\"Custom tool to search WeatherAPI for current weather.\"\"\"\n",
        "  base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
        "  complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
        "\n",
        "  ## get API response\n",
        "  response = requests.get(complete_url)\n",
        "  data = response.json()\n",
        "  if data.get(\"location\"):\n",
        "    return data\n",
        "  else:\n",
        "    return \"Weather Data Not Found!\""
      ],
      "metadata": {
        "id": "gWkiAQskkeBE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Tool Calling with LLM"
      ],
      "metadata": {
        "id": "FJ-GhlB8meWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "##setup LLM\n",
        "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
        "tools = [search_web, get_weather]\n",
        "\n",
        "## instantiate tools\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "3mcIEmFsmWyb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## prompt test\n",
        "prompt = \"Who won the Stanley Cup in 2011\"\n",
        "response = llm_with_tools.invoke(prompt)\n",
        "response.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB8luRXVm1AF",
        "outputId": "301fff3c-93fc-420b-b9a2-3be8b3a3ff15"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## prompt test\n",
        "prompt = \"how is the weather in Denver today?\"\n",
        "response = llm_with_tools.invoke(prompt)\n",
        "response.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp3QD1Lcm-bU",
        "outputId": "ca5e7c93-0543-4e28-dedc-ab0c4f556335"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'get_weather',\n",
              "  'args': {'query': 'Denver'},\n",
              "  'id': 'call_0emVUQf3inBMI0J81WU43KVu',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build and Test AI Agent\n",
        "* We now have tools defined and the LLM setup, so we can create an agent.\n",
        "* We will be using a tool calling agent to bind the tools to the agent with a prompt.\n",
        "* We will also add in the capability to store historical conversations as memory."
      ],
      "metadata": {
        "id": "dBMz_2SMoVCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "## system prompt\n",
        "SYS_PROMPT = \"\"\"Act as a helpful assistant.\n",
        "                Use the tools at your disposal to perform tasks as needed.\n",
        "                  - get_weather: whenever user asks get the weather of a location.\n",
        "                  - search_web: whenever user asks for information on current events or if you don't know the answer.\n",
        "            \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
        "        (\"human\", \"{query}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_template.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThQLALn_oL7X",
        "outputId": "4bdb4ea2-47ee-4e9b-cc31-0dfc6623864e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"Act as a helpful assistant.\\n                Use the tools at your disposal to perform tasks as needed. \\n                  - get_weather: whenever user asks get the weather of a location.\\n                  - search_web: whenever user asks for information on current events or if you don't know the answer.\\n            \")),\n",
              " MessagesPlaceholder(variable_name='history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}')),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary so far:\n",
        "* Now we can initialize the agent with the LLM, the prompt, and the tools.\n",
        "* The agent is responsible for taking input and deciding what actions to take.\n",
        "* REMEMBER the Agent does NOT execute those actions --- that is done by the `AgentExecutor`\n",
        "* Note that we are passing in the model the LLM (`llm`) NOT the `llm_with_tools`.\n",
        "  * That is because the `create_tool_calling_agent` will call `.bind_tools` for us under the hood.\n",
        "  * This should ideally be used with an LLM which suppors tool/function calling."
      ],
      "metadata": {
        "id": "p2EjrbCFuF-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "\n",
        "## agent\n",
        "agent = create_tool_calling_agent(llm, tools, prompt_template)\n",
        "agent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0ArelJ_sQXv",
        "outputId": "e63e5464-bee2-4fc8-fa38-eebb6290787d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunnableAssign(mapper={\n",
              "  agent_scratchpad: RunnableLambda(lambda x: format_to_tool_messages(x['intermediate_steps']))\n",
              "})\n",
              "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'query'], optional_variables=['history'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"Act as a helpful assistant.\\n                Use the tools at your disposal to perform tasks as needed. \\n                  - get_weather: whenever user asks get the weather of a location.\\n                  - search_web: whenever user asks for information on current events or if you don't know the answer.\\n            \")), MessagesPlaceholder(variable_name='history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
              "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f25154f6800>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f2515520160>, model_name='gpt-4o', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'search_web', 'description': 'Custom tool to search web for a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'get_weather', 'description': 'Custom tool to search WeatherAPI for current weather.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}}, 'required': ['query']}}}]})\n",
              "| ToolsAgentOutputParser()"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we combine the `agent` (the brains) with the `tools` inside the `AgentExecutor` which will repeatedly call the agent and execute tools."
      ],
      "metadata": {
        "id": "l-0tJ1s7xOlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "## agent executor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
        "agent_executor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NGP7H-FxNKq",
        "outputId": "7f872336-9ab4-4a3e-fef6-97126ae906b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentExecutor(agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
              "  agent_scratchpad: RunnableLambda(lambda x: format_to_tool_messages(x['intermediate_steps']))\n",
              "})\n",
              "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'query'], optional_variables=['history'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"Act as a helpful assistant.\\n                Use the tools at your disposal to perform tasks as needed. \\n                  - get_weather: whenever user asks get the weather of a location.\\n                  - search_web: whenever user asks for information on current events or if you don't know the answer.\\n            \")), MessagesPlaceholder(variable_name='history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
              "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f25154f6800>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f2515520160>, model_name='gpt-4o', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'search_web', 'description': 'Custom tool to search web for a query.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'get_weather', 'description': 'Custom tool to search WeatherAPI for current weather.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}}, 'required': ['query']}}}]})\n",
              "| ToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[StructuredTool(name='search_web', description='Custom tool to search web for a query.', args_schema=<class 'pydantic.v1.main.search_webSchema'>, func=<function search_web at 0x7f252fdee560>), StructuredTool(name='get_weather', description='Custom tool to search WeatherAPI for current weather.', args_schema=<class 'pydantic.v1.main.get_weatherSchema'>, func=<function get_weather at 0x7f252fdeed40>)])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## now send query to agent\n",
        "query = \"\"\"Tell me who won the Stanley Cup in 2024,\n",
        "        show me some detailed information about the game.\n",
        "        \"\"\"\n",
        "response = llm.invoke(query)\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "vWaBqcPlxda9",
        "outputId": "ec02e08f-d705-4d29-9fe7-5e54bf572cdf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, but I can't provide real-time information or future events as my knowledge was last updated in October 2021. For the most current information on the Stanley Cup winner in 2024 and detailed information about the game, I recommend checking the latest sports news websites, the official NHL website, or other reliable sources.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the model does not know anything past a certain date so we can now use our agent to answer the query."
      ],
      "metadata": {
        "id": "ZPKb0ufjy2Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## now send query to agent\n",
        "query = \"\"\"Tell me who won the Stanley Cup in 2024,\n",
        "        show me some detailed information about the game.\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})"
      ],
      "metadata": {
        "id": "CT33VZKMy9fy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## get response from agent executor\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThFRgeOnzFsY",
        "outputId": "222636af-2929-4795-a943-a1ad1937ecbb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Tell me who won the Stanley Cup in 2024,\\n        show me some detailed information about the game.\\n        ',\n",
              " 'output': \"The Florida Panthers won the 2024 Stanley Cup, defeating the Edmonton Oilers in a thrilling seven-game series. This victory marked the Panthers' first championship in their thirty-year history. \\n\\nIn the decisive Game 7, the Panthers edged out the Oilers with a 2-1 victory. This win was a culmination of the 2023-24 NHL season and the 2024 Stanley Cup playoffs. \\n\\nFor more detailed information, you can check the [Wikipedia page](https://en.wikipedia.org/wiki/2024_Stanley_Cup_Finals) or the [Sporting News article](https://www.sportingnews.com/us/nhl/news/oilers-panthers-live-score-results-game-7-stanley-cup-final/73fb8b4b6c2b7816e0199225).\"}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## cleanup the output with markdown\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "s7yceIvjzIq2",
        "outputId": "e94f4ea7-7d7a-43a8-8031-6feba9228020"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The Florida Panthers won the 2024 Stanley Cup, defeating the Edmonton Oilers in a thrilling seven-game series. This victory marked the Panthers' first championship in their thirty-year history. \n\nIn the decisive Game 7, the Panthers edged out the Oilers with a 2-1 victory. This win was a culmination of the 2023-24 NHL season and the 2024 Stanley Cup playoffs. \n\nFor more detailed information, you can check the [Wikipedia page](https://en.wikipedia.org/wiki/2024_Stanley_Cup_Finals) or the [Sporting News article](https://www.sportingnews.com/us/nhl/news/oilers-panthers-live-score-results-game-7-stanley-cup-final/73fb8b4b6c2b7816e0199225)."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## now lets try a weather query\n",
        "query = \"\"\"What is the weather in Denver, CO today?\n",
        "        \"\"\"\n",
        "\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "vf1rs_9hzU1f",
        "outputId": "dbb0b28e-5679-47f5-cb49-19e23c280806"
      },
      "execution_count": 26,
      "outputs": [
        {
          "data": {
            "text/markdown": "The current weather in Denver, CO is partly cloudy with a temperature of 29.7°C (85.5°F). The wind is coming from the west-northwest at 2.2 mph (3.6 kph). The humidity is quite low at 6%, and there is no precipitation. The UV index is 8, indicating a high level of UV radiation, so take precautions if you're spending time outdoors. Visibility is good at 16 km (9 miles).",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## how about another weather query\n",
        "query = \"\"\"What is the weather today in Stowe, VT?\n",
        "        \"\"\"\n",
        "\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "Go39_iIczl74",
        "outputId": "ab9848b3-7e8e-49f0-92a2-dbda90a6681d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The weather in Stowe, VT today is partly cloudy. The current temperature is 18.9°C (66.0°F). The wind is blowing from the south at 6.0 mph (9.7 kph). The humidity is at 54%, and visibility is 16 km (9 miles). The UV index is 3. \n\n![Partly cloudy](//cdn.weatherapi.com/weather/64x64/day/116.png)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## continue the conversation\n",
        "query = \"\"\"Which city is colder?\"\"\"\n",
        "\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "EXBiq62xz0LJ",
        "outputId": "c75a6cc8-5fcc-4e0d-afbd-3d81b081f9d9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Could you please specify the cities you would like to compare in terms of temperature?"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "* AHA! We have not used memory yet to store this."
      ],
      "metadata": {
        "id": "bZ2T__5F0PHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build and Test Multi-User Conversational AI Agent\n",
        "* We will now implement the `SQLChatMessageHistory` to store separate conversation histories per user or session.\n",
        "* This will help us build a conversational Agentic Chatbot which will be accessed by many users at the same time."
      ],
      "metadata": {
        "id": "ccMpcomT02-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## removes memory database file -- usually not needed\n",
        "# you can run this only when you want to remove ALL conversation histories\n",
        "## ok if you get rm: cannot remove 'memory.db`: No such file or directory because initially no memory exists\n",
        "!rm memory.db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIsKBm4M0J7E",
        "outputId": "612fec6e-19f3-486b-9d10-4ab44ebba164"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'memory.db': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "\n",
        "## used to retrieve conversation history from database\n",
        "## based on specific user or session ID\n",
        "def get_session_history_db(session_id):\n",
        "  \"\"\"Takes in session history and returns chat history from sqlite db\"\"\"\n",
        "  return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")\n",
        "\n",
        "\n",
        "## creates converation chain + agent which can load memory based on specific user or session id\n",
        "agentic_chatbot = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_session_history_db,\n",
        "    input_messages_key='query', ##input prompt\n",
        "    history_messages_key='history' ##history stored here\n",
        ")\n",
        "\n",
        "## function to call agent show results per user session\n",
        "from IPython.display import display, Markdown\n",
        "def chat_with_agent(prompt: str, session_id: str):\n",
        "  response = agentic_chatbot.invoke({\"query\": prompt},\n",
        "                                    {'configurable': { 'session_id': session_id}})\n",
        "  display(Markdown(response['output']))"
      ],
      "metadata": {
        "id": "cMFRHAXZ1XRQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulate User 1 using the agent"
      ],
      "metadata": {
        "id": "nGEZhvQn3f5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 'tom001'\n",
        "prompt = 'Hello can you tell me who won the Superbowl in 2024'\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "rSgPwr3d2-Rh",
        "outputId": "812f8838-601b-43dd-e701-3c6883dfe7d7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The Kansas City Chiefs won the Super Bowl in 2024, defeating the San Francisco 49ers 25-22 in overtime. This victory marked the Chiefs' third Super Bowl win in five years and their second consecutive title."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## continuing conversation\n",
        "prompt = \"Tell me more about this event in detail please\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "4aLPllzZ3rW7",
        "outputId": "9ef94fa1-da44-4656-f2d6-f31b08b460e4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The Kansas City Chiefs won the Super Bowl in 2024, defeating the San Francisco 49ers 25-22 in an exciting overtime game. This victory marked the Chiefs' third Super Bowl win in five years and their second consecutive title. The game was held at Allegiant Stadium in Las Vegas on February 11, 2024.\n\nKey highlights of the game include:\n\n- The Chiefs' star quarterback, Patrick Mahomes, played a crucial role in the victory, throwing the game-winning touchdown pass to wide receiver Mecole Hardman Jr. during overtime.\n- The game was only the second overtime match in Super Bowl history.\n- The Chiefs' defense, led by a signature blitz from Steve Spagnuolo, forced a critical field goal from the 49ers late in the fourth quarter.\n- San Francisco 49ers' running back Christian McCaffrey scored a touchdown during the first half, showcasing the 49ers' strong offensive capabilities.\n- The Chiefs embraced an underdog mentality throughout the postseason, upsetting three teams to secure their second consecutive Super Bowl title.\n\nThe Chiefs' victory was celebrated with a steely resolve, as they arrived at the stadium in all black, signaling their determination to win against the NFC's best offensive team."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulate User 2 using the agent"
      ],
      "metadata": {
        "id": "58A1XOd639KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = \"taylor1989\"\n",
        "prompt = \"how is the weather in Denver, CO today? Please show detailed stats\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "w5UUo5nB32tV",
        "outputId": "049113e8-4f33-474d-83ee-944ba5e7bdd9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The weather in Denver, CO today is sunny. Here are the detailed statistics:\n\n- **Temperature**: 31.4°C (88.5°F)\n- **Feels Like**: 29.2°C (84.5°F)\n- **Wind**: 6.5 mph (10.4 kph) from the northwest (NW)\n- **Wind Gusts**: Up to 7.5 mph (12.0 kph)\n- **Humidity**: 10%\n- **Pressure**: 1017.0 mb (30.03 in)\n- **Precipitation**: 0.0 mm (0.0 in)\n- **Cloud Cover**: 0% (Clear skies)\n- **Visibility**: 48.0 km (29.0 miles)\n- **UV Index**: 8.0 (Very High)\n- **Dew Point**: -3.0°C (26.6°F)\n\n![Weather Icon](//cdn.weatherapi.com/weather/64x64/day/113.png)\n\nIt's a clear and sunny day with very low humidity, so make sure to stay hydrated and protect yourself from the sun if you're spending time outdoors!"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## continue conversation\n",
        "user_id = \"taylor1989\"\n",
        "prompt = \"What about Vail?\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "yIGrJN5h4NLR",
        "outputId": "a358936f-b192-45f4-8e02-df5a636998ae"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The weather in Vail, CO today is sunny. Here are the detailed statistics:\n\n- **Temperature**: 15.1°C (59.2°F)\n- **Feels Like**: 15.1°C (59.2°F)\n- **Wind**: 11.2 mph (18.0 kph) from the west-northwest (WNW)\n- **Wind Gusts**: Up to 12.9 mph (20.7 kph)\n- **Humidity**: 14%\n- **Pressure**: 1035.0 mb (30.56 in)\n- **Precipitation**: 0.0 mm (0.0 in)\n- **Cloud Cover**: 0% (Clear skies)\n- **Visibility**: 16.0 km (9.0 miles)\n- **UV Index**: 5.0 (Moderate)\n- **Dew Point**: -4.6°C (23.7°F)\n\n![Weather Icon](//cdn.weatherapi.com/weather/64x64/day/113.png)\n\nIt's a clear and sunny day in Vail with low humidity. Enjoy the beautiful weather!"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## continue conversation\n",
        "user_id = \"taylor1989\"\n",
        "prompt = \"which city is warmer?\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "-6DMC4VK4bj6",
        "outputId": "4c6b1a3e-7f62-4884-953a-c05eb5434e19"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Denver, CO is warmer than Vail, CO today. \n\n- **Denver**: 31.4°C (88.5°F)\n- **Vail**: 15.1°C (59.2°F)\n\nDenver's temperature is significantly higher than Vail's."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVglx2Vd4jv4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}